# 实验2-通过Shell进行文件操作

## 实验目的

通过Shell完成以下工作：

- 查看目录
- 创建目录
- 复制本地文件到HDFS
- 剪切本地文件到HDFS
- 显示文件内容
- 显示文件的末尾
- 追加一个文件到已经存在的文件的末尾
- 传输HDFS文件到本地
- 从HDFS一个路径拷贝到HDFS的另一个路径
- 从HDFS一个路径剪切到HDFS的另一个路径
- 合并下载多个HDFS文件
- 统计文件夹大小
- 删除文件
- 删除目录
- 修改一个HDFS文件的副本数，并观察实际生效情况
- 创建一个小于128MB的HDFS文件，观察该文件在DataNode上的数据块数量、具体物理存放位置、占用磁盘的实际大小
- 创建一个大于128M的HDFS文件，观察该文件在DataNode上的数据块数量、具体物理存放位置、占用磁盘的实际大小



## 查看目录

```bash
hdfs dfs -ls /

# 递归列出所有文件
hdfs dfs -ls -R /
```

## 创建目录

```bash
hdfs dfs -mkdir -p /user/root/input
```

## 复制本地文件到HDFS

```bash
ls > ./data.txt
# 两种方式
hdfs dfs -put ./data.txt /user/root/input/
hdfs dfs -copyFromLocal ./data.txt /user/root/input/
```

## 剪切本地文件到HDFS

```bash
hdfs dfs -moveFromLocal ./data.txt /user/root/input/
```

## 显示文件内容

```bash
hdfs dfs -cat /user/root/input/data.txt
```

## 显示文件的末尾

```bash
hdfs dfs -tail /user/root/input/data.txt
```

## 追加一个文件到已经存在的文件的末尾

```bash
hdfs dfs -appendToFile ./append.txt /user/root/input/data.txt
```

## 传输HDFS文件到本地

```bash
# 两种方式
hdfs dfs -get /user/root/input/data.txt ./data1.txt
hdfs dfs -copyToLocal /user/root/input/data.txt ./data1.txt
```

## 从HDFS一个路径拷贝到HDFS的另一个路径

```bash
hdfs dfs -cp /user/root/input/data.txt /user/root/output/
```

## 从HDFS一个路径剪切到HDFS的另一个路径

```bash
hdfs dfs -mv /user/root/input/data.txt /user/root/output/data2.txt
```

## 合并下载多个HDFS文件，比如 HDFS的/user/root/input 下有多个文件：split.1、split.2、split.3…… 

```bash
hdfs dfs -getmerge /user/root/input/split.* ./merge.txt
```

## 统计文件夹大小

```bash
# 查看目录大小
hdfs dfs -du -s -h /user/root/input

# 查看目录下文件大小
hdfs dfs -du -h /user/root/input
```

## 删除文件

```bash
hdfs dfs -rm /user/root/input/data.txt
```

## 删除目录

```bash
hdfs dfs -rmdir /user/root/input/
hdfs dfs -rm -r /user/root/input/
```

## 修改一个HDFS文件的副本数，并观察实际生效情况

```bash
hdfs dfs -setrep 3 /user/root/input/data.txt
```

## 创建一个小于128MB的HDFS文件，观察该文件在DataNode上的数据块数量、具体物理存放位置、占用磁盘的实际大小

```bash
# 查看HDFS文件在Linux上的存放位置
hdfs fsck /user/root/input/data.txt -files -blocks -locations -racks

# 查找数据存放位置 查看配置中属性 dfs.datanode.data.dir

# 根据上一步查询出的数据块id（以blk开头） 在HDFS data目录下找到该文件
find /opt/hadoop/data/tmp/ -name blk_1073741825*

# 查看该文件大小
ll -sh /opt/hadoop/data/tmp/dfs/data/current/BP-646611727-10.244.5.30-1565144248715/current/finalized/subdir0/subdir0/blk_1073741830
```

## 创建一个大于128M的HDFS文件，观察该文件在DataNode上的数据块数量、具体物理存放位置、占用磁盘的实际大小（选做）

```bash
# 创建一个150M的文件
dd if=/dev/urandom of=150M.txt bs=10M count=15

# 上传该文件
hdfs dfs -copyFromLocal ./150M.txt /user/root/input

# 查看HDFS文件在Linux上的存放位置
hdfs fsck /user/root/input/150M.txt -files -blocks -locations -racks

# 根据上一步查询出的数据块id（以blk开头） 在HDFS data目录下找到该文件
find /opt/hadoop/data/tmp/ -name blk_1073741826*

# 查看该文件大小
ll -sh /opt/hadoop/data/tmp/dfs/data/current/BP-998979426-10.244.11.74-1565226161118/current/finalized/subdir0/subdir0/blk_1073741826

# 查找第2个数据块及文件大小
find /opt/hadoop/data/tmp/ -name blk_1073741827*
ll -sh /opt/hadoop/data/tmp/dfs/data/current/BP-998979426-10.244.11.74-1565226161118/current/finalized/subdir0/subdir0/blk_1073741827
```


